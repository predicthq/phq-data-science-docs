{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed to provide you with the context you need to get started with the [Beam API ](https://docs.predicthq.com/resources/beam) and use it effectively.\n",
    "\n",
    "[Beam](https://www.predicthq.com/beam) is PredictHQ's automated correlation engine to accurately reveal the events that drive demand for your business. As well as showing you the correlation between events and your demand data. Beam can also decompose your demand data which can help improve your demand forecasting accuracy. For more information on Beam see the [Beam Overview](https://www.predicthq.com/support/beam-overview).\n",
    "\n",
    "Our objective is to facilitate three essential use cases through the Beam APIs: bulk data uploading, data decomposition retrieval, and important feature identification. The bulk upload feature empowers you to generate multiple analyses simultaneously from your source data. In contrast, the Beam decomposed data feature empowers you to extract decomposed results using the Beam API after their data has been uploaded. The final identifying important feature enables you to identify features and event categories that are highly likely to be relevant to your forecasting model.\n",
    "\n",
    "Utilizing the decomposition of your demand data can enhance the accuracy of your forecasts. If you currently do not decompose your data for forecasting purposes, you can leverage Beam's decomposition functionality to obtain a breakdown of your data. Beam's decomposition process separates your data into baseline demand and remainder components. Improved decomposition data can lead to enhanced forecast accuracy.\n",
    "\n",
    "1. [Uploading location and demand data to Beam](#part-1-uploading-location-and-demand-data-to-beam)\n",
    "2. [Generating Beam correlation results](#part-2-generating-correlation-results)\n",
    "3. [Identifying important features](#part-3-identifying-important-features)\n",
    "4. [Plotting and interpretation](#part-4-plotting-and-interpretation) \n",
    "\n",
    "For more information on Beam API see our [technical documentation](https://docs.predicthq.com/resources/beam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os \n",
    "import requests\n",
    "import plotly.graph_objects as go\n",
    "from predicthq import Client\n",
    "import collections\n",
    "import numpy as np\n",
    "from datetime import datetime, date, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If using Google Colab uncomment the following code block, this is used to download a repo that contains sample data used for this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/predicthq/phq-data-science-docs.git\n",
    "# %cd phq-data-science-docs/beam-api-notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Uploading location and demand data to Beam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beam works by creating an analysis for each location. A location is usually associated with a physical business location such as a store, hotel, or some other type of office or business location. For example, in a restaurant chain, you may have a location for each restaurant.\n",
    "\n",
    "When running Beam, you execute it over a set of locations and create a Beam analysis for each location. Then, for each location, you upload your historical demand data, such as historical retail sales data or historical hotel room booking data. This is the demand data that Beam correlates with event data. For each location, you need the latitude and longitude information. Our [Suggested Radius API](https://docs.predicthq.com/resources/suggested-radius) will calculate the radius for you.\n",
    "\n",
    "The example code below loops over a list of input locations, creates a Beam analysis for each location, and uploads demand data for each location. If you are adapting this for your context, you may be loading demand data from a database and an API to upload into Beam.\n",
    "\n",
    "You can use this approach to upload data for hundreds or thousands of locations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Upload a location file to get suggested radii with suggested radius API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This provided ACCESS_TOKEN is limited to the demo example.The following link will guide you through creating an account and an access token. Please make sure your API token is up-to-date to identify feature importance. \n",
    "https://docs.predicthq.com/guides/quickstart/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_TOKEN = 'Uuv2xci7wNAU4NHPBZTmY5KqGiIjdw4ymTMlDc_g'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the directory where the data is stored\n",
    "demand_data_wd = '/Users/charlottegao/Desktop/RND/Beam/beam_analyses/demand_data_wd'\n",
    "# Read in a CSV file with latitude and longitude data for each location\n",
    "locations = pd.read_csv(f'{demand_data_wd}/location_sample.csv')\n",
    "# Set urls for API requests\n",
    "SUGGESTED_RADIUS_URL=\"https://api.predicthq.com/v1/suggested-radius/\"\n",
    "BEAM_URL = \"https://api.predicthq.com/v1/beam/analyses\"\n",
    "FEATURES_API_URL = \"https://api.predicthq.com/v1/features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>store_0</td>\n",
       "      <td>37.784</td>\n",
       "      <td>-122.404</td>\n",
       "      <td>restaurants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>store_1</td>\n",
       "      <td>47.611</td>\n",
       "      <td>-122.338</td>\n",
       "      <td>restaurants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>store_2</td>\n",
       "      <td>40.735</td>\n",
       "      <td>-73.869</td>\n",
       "      <td>restaurants</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location_id     lat      lon     industry\n",
       "0     store_0  37.784 -122.404  restaurants\n",
       "1     store_1  47.611 -122.338  restaurants\n",
       "2     store_2  40.735  -73.869  restaurants"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_suggested_radius(lat_lon, industry, radius_unit):\n",
    "    \"\"\"\n",
    "    Returns the suggested radius for a given latitude and longitude.\n",
    "\n",
    "    Args:\n",
    "        lat_lon (str): The latitude and longitude of the location in the format \"lat,lon\".\n",
    "        industry (str): The industry of interest that the radius will be calculated for. \n",
    "        radius_unit (str): Unit in which the suggested radius will be returned.\n",
    "        \n",
    "    Returns:\n",
    "        float: The suggested radius in your perferred unit.\n",
    "    \"\"\"\n",
    "     # Set the url for the API call\n",
    "    url = SUGGESTED_RADIUS_URL\n",
    "    # Set the query parameters for the API call\n",
    "    params = {\n",
    "        \"location.origin\": lat_lon,\n",
    "        \"industry\": industry, \n",
    "        \"radius_unit\": radius_unit \n",
    "    }\n",
    "     # Set the headers for the API call (including the access token)\n",
    "    headers={\n",
    "              \"Authorization\": \"Bearer \" + ACCESS_TOKEN,\n",
    "              \"Accept\": \"application/json\"\n",
    "            }\n",
    "    # Make the API call and get the JSON response\n",
    "    response = requests.get(url, params=params, headers=headers).json()\n",
    "    # Extract the radius from the JSON response and return it\n",
    "    radius =  response['radius']\n",
    "    return radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the suggested radius for each location\n",
    "rads = []\n",
    "# Please specify your preferred unit here\n",
    "radius_unit = 'km'\n",
    "# Loop through each row in the locations dataframe to generate the suggested radius for each location\n",
    "for index, location in locations.iterrows():\n",
    "    # Call the get_suggested_radius function to get the suggested radius for each location\n",
    "    r = get_suggested_radius(f\"{location['lat']}, {location['lon']}\", {location['industry']}, radius_unit)\n",
    "    # Append the suggested radius to the list\n",
    "    rads.append(r)\n",
    "\n",
    "# Add a new column to the locations dataframe to store the suggested radii\n",
    "locations[f\"suggested_radius\"] = rads\n",
    "# Add a new column to the locations dataframe to store the suggested radii units\n",
    "locations[f\"unit\"] = radius_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>industry</th>\n",
       "      <th>suggested_radius</th>\n",
       "      <th>unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>store_0</td>\n",
       "      <td>37.784</td>\n",
       "      <td>-122.404</td>\n",
       "      <td>restaurants</td>\n",
       "      <td>2.08</td>\n",
       "      <td>km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>store_1</td>\n",
       "      <td>47.611</td>\n",
       "      <td>-122.338</td>\n",
       "      <td>restaurants</td>\n",
       "      <td>2.11</td>\n",
       "      <td>km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>store_2</td>\n",
       "      <td>40.735</td>\n",
       "      <td>-73.869</td>\n",
       "      <td>restaurants</td>\n",
       "      <td>2.10</td>\n",
       "      <td>km</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location_id     lat      lon     industry  suggested_radius unit\n",
       "0     store_0  37.784 -122.404  restaurants              2.08   km\n",
       "1     store_1  47.611 -122.338  restaurants              2.11   km\n",
       "2     store_2  40.735  -73.869  restaurants              2.10   km"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Get an analysis_id with Beam API for each analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set parameters for the Beam API, you can refer to our documentation available at [Beam API](https://docs.predicthq.com/resources/beam). It provides detailed information on how to configure the API according to your requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please specify a rank threshold for the Beam analysis, this will also be used to extract event features from Features API\n",
    "RANK_THRESHOLD = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_analysis_ids(location_id, lat, lon, radius, radius_unit, rank_threshold = RANK_THRESHOLD):\n",
    "    \"\"\"\n",
    "    Generates an analysis ID for a given location, latitude, longitude, radius and its unit.\n",
    "\n",
    "    Args:\n",
    "        location_id (str): The unique ID of the location to generate an analysis for.\n",
    "        lat (float): The latitude of the location.\n",
    "        lon (float): The longitude of the location.\n",
    "        radius (float): The radius to use for the analysis.\n",
    "        radius_unit(str): The unit of measurement used for radius. \n",
    "        rank_threshold (int): The minimum rank threshold for the analysis.\n",
    "\n",
    "    Returns:\n",
    "        str: The analysis ID generated by the API.\n",
    "    \"\"\"\n",
    "    # Set the URL and JSON payload for the API call\n",
    "    url = BEAM_URL\n",
    "    json = {\n",
    "            \"name\": f\"{location_id}_analysis\",\n",
    "                \"location\": {\n",
    "                    \"geopoint\": {\n",
    "                        \"lat\": lat,\n",
    "                        \"lon\": lon,\n",
    "                    },\n",
    "                    \"radius\": radius,\n",
    "                    \"unit\": radius_unit \n",
    "                },\n",
    "                \"rank\": {\n",
    "                    \"type\": \"phq\",\n",
    "                \"levels\": {\n",
    "                \"phq\": {\n",
    "                 \"min\": rank_threshold\n",
    "                    }\n",
    "                    }\n",
    "                },\n",
    "                \"tz\": \"UTC\"\n",
    "            }\n",
    "    # Make a POST request to the API to generate the analysis ID\n",
    "    response = requests.post(\n",
    "            url = url,\n",
    "            headers={\n",
    "                \"Authorization\": \"Bearer \" + ACCESS_TOKEN,\n",
    "                \"Accept\": \"application/json\"},\n",
    "            json = json)\n",
    "    # Extract the analysis ID from the JSON response and return it\n",
    "    return response.json()['analysis_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_ids = []\n",
    "# Loop through each row in the locations dataframe\n",
    "for index, location in locations.iterrows():\n",
    "    # Generate a Beam analysis id for each location\n",
    "    r = generate_analysis_ids(location['location_id'], str(location['lat']), str(location['lon']), location['suggested_radius'], location['unit'])\n",
    "    # Add the analysis ids to the list\n",
    "    analysis_ids.append(r)\n",
    "locations['analysis_id'] = analysis_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>industry</th>\n",
       "      <th>suggested_radius</th>\n",
       "      <th>unit</th>\n",
       "      <th>analysis_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>store_0</td>\n",
       "      <td>37.784</td>\n",
       "      <td>-122.404</td>\n",
       "      <td>restaurants</td>\n",
       "      <td>2.08</td>\n",
       "      <td>km</td>\n",
       "      <td>zqtAJYuG4tw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>store_1</td>\n",
       "      <td>47.611</td>\n",
       "      <td>-122.338</td>\n",
       "      <td>restaurants</td>\n",
       "      <td>2.11</td>\n",
       "      <td>km</td>\n",
       "      <td>ute9ZAJJhBY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>store_2</td>\n",
       "      <td>40.735</td>\n",
       "      <td>-73.869</td>\n",
       "      <td>restaurants</td>\n",
       "      <td>2.10</td>\n",
       "      <td>km</td>\n",
       "      <td>Pn7xfKyRDMk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location_id     lat      lon     industry  suggested_radius unit  \\\n",
       "0     store_0  37.784 -122.404  restaurants              2.08   km   \n",
       "1     store_1  47.611 -122.338  restaurants              2.11   km   \n",
       "2     store_2  40.735  -73.869  restaurants              2.10   km   \n",
       "\n",
       "   analysis_id  \n",
       "0  zqtAJYuG4tw  \n",
       "1  ute9ZAJJhBY  \n",
       "2  Pn7xfKyRDMk  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Upload the corresponding demand data with the generated analysis_id to Beam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example below is reading demand data from multiple businss locations from a single CSV file. When you use this in the context of your business you could read the demand data from a database, API or internal product for example. Your demand data needs to be aggregated to daily values for each given location, where date is YYYY-MM-DD format and demand is a numeric value. Please ensure that your demand data file contains both of two columns: date and demand.  See the example files for how the data should be formatted and Upload Demand Data to an Analysis in the [Beam API](https://docs.predicthq.com/resources/beam) documentation for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The request has been accepted for processing.\n",
      "The request has been accepted for processing.\n",
      "The request has been accepted for processing.\n"
     ]
    }
   ],
   "source": [
    "# Read in the data and loop through the locations_ids\n",
    "demand_data = pd.read_csv(f'{demand_data_wd}/demand_data_sample.csv')\n",
    "grouped = demand_data.groupby('location_id')\n",
    "for location_id, grouped_data in grouped:\n",
    "    # Get the corresponding analysis id for each store\n",
    "    analysis_id = locations[locations['location_id'] == location_id]['analysis_id'].values[0]\n",
    "    # Only get date and demand from grouped_data\n",
    "    individual_demand = grouped_data[['date', 'demand']]\n",
    "    # Covert individual_demand to json format\n",
    "    individual_demand_json = individual_demand.to_json(orient='records')\n",
    "    # Upload the individual_demand data to Beam\n",
    "    response = requests.post(\n",
    "    url=f\"{BEAM_URL}/{analysis_id}/sink\",\n",
    "    headers={\n",
    "        \"Authorization\": \"Bearer \" + ACCESS_TOKEN,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    },\n",
    "    data = individual_demand_json\n",
    "    )\n",
    "    # Check the status code of the response to see if the request has been accepted\n",
    "    if response.status_code== 202:\n",
    "        print('The request has been accepted for processing.') \n",
    "    else:\n",
    "        print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Check the readiness_status before correlating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can make a request to the Beam API to retrieve the analysis data for each location. The \"readiness_status\" indicates whether the data has been successfully uploaded and processed. Please ensure that the readiness_status is \"ready\" before you continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store_0_analysis: ready\n",
      "store_1_analysis: ready\n",
      "store_2_analysis: ready\n"
     ]
    }
   ],
   "source": [
    "# Please ensure that the readiness_status is \"ready\" before you continue, this might take a couple of minutes\n",
    "for index, location in locations.iterrows():\n",
    "    response = requests.get(\n",
    "    url = f\"{BEAM_URL}/{location['analysis_id']}\",\n",
    "    headers = {\n",
    "      \"Authorization\": \"Bearer \" + ACCESS_TOKEN,\n",
    "      \"Accept\": \"application/json\"\n",
    "    })\n",
    "    print(f\"{response.json()['name']}: {response.json()['readiness_status']}\")\n",
    "    # print(response.json()) # uncomment this line if you want more information about the analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>industry</th>\n",
       "      <th>suggested_radius</th>\n",
       "      <th>unit</th>\n",
       "      <th>analysis_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>store_0</td>\n",
       "      <td>37.784</td>\n",
       "      <td>-122.404</td>\n",
       "      <td>restaurants</td>\n",
       "      <td>2.08</td>\n",
       "      <td>km</td>\n",
       "      <td>zqtAJYuG4tw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>store_1</td>\n",
       "      <td>47.611</td>\n",
       "      <td>-122.338</td>\n",
       "      <td>restaurants</td>\n",
       "      <td>2.11</td>\n",
       "      <td>km</td>\n",
       "      <td>ute9ZAJJhBY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>store_2</td>\n",
       "      <td>40.735</td>\n",
       "      <td>-73.869</td>\n",
       "      <td>restaurants</td>\n",
       "      <td>2.10</td>\n",
       "      <td>km</td>\n",
       "      <td>Pn7xfKyRDMk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location_id     lat      lon     industry  suggested_radius unit  \\\n",
       "0     store_0  37.784 -122.404  restaurants              2.08   km   \n",
       "1     store_1  47.611 -122.338  restaurants              2.11   km   \n",
       "2     store_2  40.735  -73.869  restaurants              2.10   km   \n",
       "\n",
       "   analysis_id  \n",
       "0  zqtAJYuG4tw  \n",
       "1  ute9ZAJJhBY  \n",
       "2  Pn7xfKyRDMk  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.  Generating correlation results\n",
    "\n",
    "Correlation results show you your decomposed demand data as well as the event impact data for each location. This is the same data that you can see in the Beam UI - see [Viewing the Time Series Impact Analysis](https://www.predicthq.com/support/viewing-the-time-series-impact-analysis). You can see correlation where there are remainder values corresponding with significant event impact values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The request has been accepted for processing.\n",
      "The request has been accepted for processing.\n",
      "The request has been accepted for processing.\n"
     ]
    }
   ],
   "source": [
    "date_col_name = 'date'\n",
    "analyses = []\n",
    "location_ids = []\n",
    "analyses_dic = {}\n",
    "for location_id, grouped_data in grouped:\n",
    "    # Get the corresponding analysis id for each store\n",
    "    analysis_id = locations[locations['location_id'] == location_id]['analysis_id'].values[0]\n",
    "    # Only use the date and demand columns from grouped_data for the API request\n",
    "    individual_demand = grouped_data[['date', 'demand']]\n",
    "    # Extract min and max dates for each store\n",
    "    min_date = individual_demand[date_col_name].min()\n",
    "    max_date = individual_demand[date_col_name].max()\n",
    "    # Set parameters for Beam API request\n",
    "    url = f\"{BEAM_URL}/{analysis_id}/correlate\"\n",
    "    url_str = ''.join(url)\n",
    "    headers = {\n",
    "            \"Authorization\": \"Bearer \" + ACCESS_TOKEN,\n",
    "            \"Accept\": \"application/json\"\n",
    "            }\n",
    "    params = {\n",
    "            \"date.gte\": min_date,\n",
    "            \"date.lte\": max_date\n",
    "            }\n",
    "\n",
    "    response = requests.get(\n",
    "        url = url_str,\n",
    "        headers = headers,\n",
    "        params = params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print('The request has been accepted for processing.')\n",
    "        analyses.append(response.json())\n",
    "        location_ids.append(location_id)\n",
    "for key, value in zip(location_ids, analyses):\n",
    "  analyses_dic[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.  Identifying important features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might need to refresh an analysis to generate insights on the most relevant categories for a location if the analysis was created previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Skip this if you're idenitying important features for newly created analyses\n",
    "# for index, location in locations.iterrows():\n",
    "#   response = requests.post(f\"{BEAM_URL}/{location['analysis_id']}/refresh\")\n",
    "#   if response.status_code == 202:\n",
    "#     print(f\"The analysis {location['analysis_id']} has been refreshed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Generate a feature importance list for each location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The request has been accepted for processing.\n",
      "The request has been accepted for processing.\n",
      "The request has been accepted for processing.\n"
     ]
    }
   ],
   "source": [
    "feature_importance_list = []\n",
    "for index, location in locations.iterrows():\n",
    "  url = f\"{BEAM_URL}/{location['analysis_id']}/feature-importance\"\n",
    "  response = requests.get(\n",
    "    url= url,\n",
    "    headers={\n",
    "      \"Authorization\": \"Bearer \" + ACCESS_TOKEN,\n",
    "      \"Accept\": \"application/json\"\n",
    "    })\n",
    "  if response.status_code == 200:\n",
    "    print('The request has been accepted for processing.')\n",
    "    feature_importance = response.json()['feature_importance']\n",
    "    feature_importance_list.append(feature_importance)\n",
    "locations['feature_importance_list'] = feature_importance_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Feature importance output interpretation\n",
    "##### Feature_group is the name of the group, which typically refers to an event category, such as concerts, conferences, etc.\n",
    "##### Features is the names of the features in the feature group. These refer directly to features available in Features API.\n",
    "##### P_value:  The p-value associated with this feature group for this analysis. It indicates how important the features in the group are in terms of demand. The lower the p-value, the more important the feature group is. \n",
    "`0 <= p-value <= 0.05: The impact is very high. ` <br>\n",
    "`0.05 < p-value <= 0.075: The impact is high. ` <br>\n",
    "`0.075 < p-value <= 0.1: The impact is moderate. ` <br>\n",
    "##### Important: A true of false value indicating whether the feature group is considered important for this analysis. Equivalent to p_value < 0.1  We suggest using this value to determine whether or not to include this group of features in your modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column to store categories where 'important' is True\n",
    "locations['important_categories'] = locations['feature_importance_list'].apply(lambda x: [item['feature_group'] for item in x if item['important']])\n",
    "\n",
    "# Add a column to store import features along with the p values \n",
    "locations['important_features'] = locations['feature_importance_list'].apply(lambda x: [item['features'][0] for item in x if item['important']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Get corresponding features from Features API\n",
    "Once you're able to identify the importance features for each location, the next step is to extract these features. This section of the notebook provides a step-by-step instruction on how to do it.  We also have [ Feature Engineering Guide ](https://github.com/predicthq/phq-data-science-docs/blob/master/feature-engineering-guide/feature_engineering_guide.ipynb) notebook that guides you in creating events-based machine learning features. The notebook also provides guidance on selecting varying radii for different features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_FORMAT = \"%Y-%m-%d\"\n",
    "\n",
    "\n",
    "phq = Client(access_token=ACCESS_TOKEN)\n",
    "\n",
    "def get_date_groups(start, end):\n",
    "    \"\"\"\n",
    "    Features API allows a range of up to 90 days, so we have to do several requests\n",
    "    \"\"\"\n",
    "\n",
    "    def _split_dates(s, e):\n",
    "        capacity = timedelta(days=90)\n",
    "        interval = 1 + int((e - s) / capacity)\n",
    "        for i in range(interval):\n",
    "            yield s + capacity * i\n",
    "        yield e\n",
    "\n",
    "    dates = list(_split_dates(start, end))\n",
    "    for i, (d1, d2) in enumerate(zip(dates, dates[1:])):\n",
    "        if d2 != dates[-1]:\n",
    "            d2 -= timedelta(days=1)\n",
    "        yield d1.strftime(DATE_FORMAT), d2.strftime(DATE_FORMAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1  Attendance based features\n",
    "Because the API call for various types of events differs slightly, we utilize different functions for extracting event features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_attended = [\n",
    "    \"phq_attendance_sports\",\n",
    "    \"phq_attendance_conferences\",\n",
    "    \"phq_attendance_expos\",\n",
    "    \"phq_attendance_concerts\",\n",
    "    \"phq_attendance_festivals\",\n",
    "    \"phq_attendance_performing_arts\",\n",
    "    \"phq_attendance_community\",\n",
    "    \"phq_attendance_school_holidays\",\n",
    "]\n",
    "# Create a new column to only include important features that are attendance based\n",
    "locations['categories_attended_important_features'] = locations['important_features'].apply(lambda x: [item for item in x if item in categories_attended])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_important_features_api_attended_data(lat, lon, start, end, radius, unit, rank_threshold, important_categories_attended):\n",
    "    \"Get attendance based features using features API\"\n",
    "    start = datetime.strptime(start, DATE_FORMAT).date()\n",
    "    end = datetime.strptime(end, DATE_FORMAT).date()\n",
    "    result = []\n",
    "    for gte, lte in get_date_groups(start, end):\n",
    "        query = {\n",
    "            \"active__gte\": gte,\n",
    "            \"active__lte\": lte,\n",
    "            \"location__geo\": {\"lat\": lat, \"lon\": lon, \"radius\": f\"{radius}{unit}\"},\n",
    "        }\n",
    "        query.update({f\"{f}__stats\": [\"sum\"] for f in important_categories_attended})\n",
    "        query.update(\n",
    "            {f\"{f}__phq_rank\": {\"gte\": rank_threshold} for f in important_categories_attended}\n",
    "        )\n",
    "\n",
    "        features = phq.features.obtain_features(**query)\n",
    "\n",
    "        for feature in features:\n",
    "            record = {}\n",
    "            for k, v in feature.to_dict().items():\n",
    "                if k == \"date\":\n",
    "                    record[k] = v.strftime(\"%Y-%m-%d\")\n",
    "                elif k in categories_attended:\n",
    "                    record[k] = v.get(\"stats\", {}).get(\"sum\")\n",
    "            result.append(record)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_col_name = 'date'\n",
    "grouped = demand_data.groupby('location_id')\n",
    "attended_data_list = []\n",
    "location_ids = []\n",
    "attended_data_dic = {}\n",
    "for location_id, grouped_data in grouped:\n",
    "    # Get the latitude and longitude for each store\n",
    "    lat = locations[locations['location_id'] == location_id]['lat'].values[0]\n",
    "    lon = locations[locations['location_id'] == location_id]['lon'].values[0]\n",
    "    # Only use the date and demand columns from grouped_data for the API request\n",
    "    individual_demand = grouped_data[['date', 'demand']]\n",
    "    # Extract min and max dates for each store\n",
    "    start = individual_demand[date_col_name].min()\n",
    "    end = individual_demand[date_col_name].max()\n",
    "    # Get suggested radius and its unit for each store\n",
    "    radius = locations[locations['location_id'] == location_id]['suggested_radius'].values[0]\n",
    "    unit = locations[locations['location_id'] == location_id]['unit'].values[0]\n",
    "    # specify the rank threshold\n",
    "    rank_threshold = 51\n",
    "    # Get the important categories attended for each store\n",
    "    categories_attended_important_features = locations[locations['location_id'] == location_id]['categories_attended_important_features'].values[0]\n",
    "    # # Get attended data from important features API\n",
    "    attended_data = get_important_features_api_attended_data(lat, lon, start, end, radius, unit, rank_threshold, categories_attended_important_features)\n",
    "    attended_data_list.append(attended_data)\n",
    "    location_ids.append(location_id)\n",
    "for key, value in zip(location_ids, attended_data_list):\n",
    "  attended_data_dic[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2  Rank based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_rank = [\n",
    "     \"phq_rank_health_warnings\",\n",
    "     \"phq_rank_observances\",\n",
    "     \"phq_rank_public_holidays\",\n",
    "     \"phq_rank_school_holidays\",\n",
    "     \"phq_rank_academic_session\",\n",
    "     \"phq_rank_academic_exam\",\n",
    "     \"phq_rank_academic_holiday\"\n",
    "]\n",
    "# Create a new column to only include important features that are rank based\n",
    "locations['categories_rank_important_features'] = locations['important_features'].apply(lambda x: [item for item in x if item in categories_rank])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_important_features_api_rank_data(lat, lon, start, end, radius, unit, important_categories_rank):\n",
    "    \" Get rank based features using features API\"\n",
    "    start = datetime.strptime(start, DATE_FORMAT).date()\n",
    "    end = datetime.strptime(end, DATE_FORMAT).date()\n",
    "\n",
    "    result = []\n",
    "    for gte, lte in get_date_groups(start, end):\n",
    "        for category in important_categories_rank:\n",
    "            # use a different radius setting for phq_rank_observances and phq_rank_public_holidays\n",
    "            if category in ['phq_rank_observances', 'phq_rank_public_holidays']:\n",
    "                # Set a specific radius for the selected categories\n",
    "                radius_for_category = \"1mi\"\n",
    "            else:\n",
    "                # Use the default radius and unit for other categories\n",
    "                radius_for_category = f\"{radius}{unit}\"\n",
    "\n",
    "            query = {\n",
    "            \"active__gte\": gte,\n",
    "            \"active__lte\": lte,\n",
    "            \"location__geo\": {\"lat\": lat, \"lon\": lon, \"radius\": radius_for_category},\n",
    "            }\n",
    "\n",
    "            query.update({f\"{f}\": True for f in important_categories_rank})\n",
    "\n",
    "            features = phq.features.obtain_features(**query)\n",
    "            for feature in features:\n",
    "                record = {}\n",
    "                for k, v in feature.to_dict().items():\n",
    "                    if k == \"date\":\n",
    "                        record[k] = v.strftime(DATE_FORMAT)\n",
    "                    elif k in categories_rank:\n",
    "                        for rank_level, level_count in v.get(\"rank_levels\", {}).items():\n",
    "                            record[f\"{k}_level_{rank_level}\"] = float(level_count)\n",
    "\n",
    "                        # sum all values\n",
    "                        record[f\"{k}\"] = sum(\n",
    "                        [\n",
    "                            float(level_count)\n",
    "                            for level_count in v.get(\"rank_levels\", {}).values()\n",
    "                        ]\n",
    "                        )\n",
    "                # keep sum of all levels only\n",
    "                for k in list(record.keys()):\n",
    "                    if \"level\" in k:\n",
    "                        del record[k]\n",
    "                result.append(record)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_col_name = 'date'\n",
    "grouped = demand_data.groupby('location_id')\n",
    "rank_data_list = []\n",
    "location_ids = []\n",
    "rank_data_dic = {}\n",
    "for location_id, grouped_data in grouped:\n",
    "    # Get the latitude and longitude for each store\n",
    "    lat = locations[locations['location_id'] == location_id]['lat'].values[0]\n",
    "    lon = locations[locations['location_id'] == location_id]['lon'].values[0]\n",
    "    # Only use the date and demand columns from grouped_data for the API request\n",
    "    individual_demand = grouped_data[['date', 'demand']]\n",
    "    # Extract min and max dates for each store\n",
    "    start = individual_demand[date_col_name].min()\n",
    "    end = individual_demand[date_col_name].max()\n",
    "    # Get suggested radius and its unit for each store\n",
    "    radius = locations[locations['location_id'] == location_id]['suggested_radius'].values[0]\n",
    "    unit = locations[locations['location_id'] == location_id]['unit'].values[0]\n",
    "    # Get the important categories attended for each store\n",
    "    categories_rank_important_features = locations[locations['location_id'] == location_id]['categories_rank_important_features'].values[0]\n",
    "    # # Get attended data from important features API\n",
    "    rank_data = get_important_features_api_rank_data(lat, lon, start, end, radius, unit, categories_rank_important_features)\n",
    "    rank_data_list.append(rank_data)\n",
    "    location_ids.append(location_id)\n",
    "for key, value in zip(location_ids, rank_data_list):\n",
    "  rank_data_dic[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3  Impact based features\n",
    "<b> Severe weahter features </b>\n",
    "\n",
    "Please note that impact-based features(Severe weahter features) are for the retail industry only. The severe weather features use demand impact patterns. Demand impact patterns calculate impact duration of a severe weather event and are based on industry specific information. Our severe weather features are currently designed and tested on data for the retail segment only. If your business is in an industry segment other than retail (e.g. accomodation or travel) then these features may not work for you or may be less effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_impact = {\n",
    "    \"phq_impact_severe_weather_air_quality_retail\",\n",
    "    \"phq_impact_severe_weather_blizzard_retail\",\n",
    "    \"phq_impact_severe_weather_cold_wave_retail\",\n",
    "    \"phq_impact_severe_weather_cold_wave_snow_retail\",\n",
    "    \"phq_impact_severe_weather_cold_wave_storm_retail\",\n",
    "    \"phq_impact_severe_weather_dust_retail\",\n",
    "    \"phq_impact_severe_weather_dust_storm_retail\",\n",
    "    \"phq_impact_severe_weather_flood_retail\",\n",
    "    \"phq_impact_severe_weather_heat_wave_retail\",\n",
    "    \"phq_impact_severe_weather_hurricane_retail\",\n",
    "    \"phq_impact_severe_weather_thunderstorm_retail\",\n",
    "    \"phq_impact_severe_weather_tornado_retail\",\n",
    "    \"phq_impact_severe_weather_tropical_storm_retail\",\n",
    "}\n",
    "# Create a new column to only include important features that are rank based\n",
    "locations['categories_impact_important_features'] = locations['important_features'].apply(lambda x: [item for item in x if item in categories_impact])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_important_features_api_impact_data(lat, lon, start, end, rank_threshold, categories_impact):\n",
    "    \" Get impact based features using features API\"\n",
    "    start = datetime.strptime(start, DATE_FORMAT).date()\n",
    "    end = datetime.strptime(end, DATE_FORMAT).date()\n",
    "\n",
    "    result = []\n",
    "    for gte, lte in get_date_groups(start, end):\n",
    "        query = {\n",
    "            \"active__gte\": gte,\n",
    "            \"active__lte\": lte,\n",
    "            \"location__geo\": {\"lat\": lat, \"lon\": lon, \"radius\": \"1mi\"},\n",
    "        }\n",
    "\n",
    "        query.update({f\"{f}__stats\": [\"max\"] for f in categories_impact})\n",
    "        query.update(\n",
    "            {f\"{f}__phq_rank\": {\"gte\": rank_threshold} for f in categories_impact}\n",
    "        )\n",
    "\n",
    "        features = phq.features.obtain_features(**query)\n",
    "\n",
    "        for feature in features:\n",
    "            record = {}\n",
    "            for k, v in feature.to_dict().items():\n",
    "                if k == \"date\":\n",
    "                    record[k] = v.strftime(\"%Y-%m-%d\")\n",
    "                else:\n",
    "                    record[k] = v.get(\"stats\", {}).get(\"max\")\n",
    "\n",
    "            result.append(record)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_col_name = 'date'\n",
    "grouped = demand_data.groupby('location_id')\n",
    "impact_data_list = []\n",
    "location_ids = []\n",
    "impact_data_dic = {}\n",
    "for location_id, grouped_data in grouped:\n",
    "    # Get the latitude and longitude for each store\n",
    "    lat = locations[locations['location_id'] == location_id]['lat'].values[0]\n",
    "    lon = locations[locations['location_id'] == location_id]['lon'].values[0]\n",
    "    # Only use the date and demand columns from grouped_data for the API request\n",
    "    individual_demand = grouped_data[['date', 'demand']]\n",
    "    # Extract min and max dates for each store\n",
    "    start = individual_demand[date_col_name].min()\n",
    "    end = individual_demand[date_col_name].max()\n",
    "    # specify the rank threshold\n",
    "    rank_threshold = 51\n",
    "    # Get the important categories attended for each store\n",
    "    try:\n",
    "        categories_impact_important_features = locations[locations['location_id'] == location_id]['categories_impact_important_features'].values[0]\n",
    "    except IndexError:\n",
    "        # Handle the case where categories_impact_important_features is empty or doesn't exist\n",
    "        categories_impact_important_features = []  # You can set it to an empty list or handle it as needed\n",
    "    # Get attended data from important features API\n",
    "    impact_data = get_important_features_api_impact_data(lat, lon, start, end, rank_threshold, categories_impact)\n",
    "    impact_data_list.append(impact_data)\n",
    "    location_ids.append(location_id)\n",
    "for key, value in zip(location_ids, impact_data_list):\n",
    "    impact_data_dic[key] = value  # Corrected dictionary name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.4  Combine the 3 different types of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dict = {}\n",
    "# Iterate through the keys in attended_data_dic\n",
    "for location_id in attended_data_dic.keys():\n",
    "    combined_dict[location_id] = []  # Initialize an empty list for the combined data\n",
    "    attended_data_dic_data = attended_data_dic[location_id]\n",
    "    rank_data_dic_data = rank_data_dic.get(location_id, [])  # Use an empty list if the key doesn't exist in dict2\n",
    "    impact_data_dic_data = impact_data_dic.get(location_id, [])  # Use an empty list if the key doesn't exist in dict3\n",
    "\n",
    "    # Iterate through the data entries in attended_data_dic\n",
    "    for entry1 in attended_data_dic_data:\n",
    "        # Find the corresponding entry in attended_data_dic_data based on the date\n",
    "        corresponding_entry2 = next((entry2 for entry2 in rank_data_dic_data if entry2['date'] == entry1['date']), None)\n",
    "        # Find the corresponding entry in impact_data_dic_data based on the date\n",
    "        corresponding_entry3 = next((entry3 for entry3 in impact_data_dic_data if entry3['date'] == entry1['date']), None)\n",
    "\n",
    "        if corresponding_entry2 and corresponding_entry3:\n",
    "            # Merge all three dictionaries for the same date\n",
    "            combined_entry = {**entry1, **corresponding_entry2, **corresponding_entry3}\n",
    "            combined_dict[location_id].append(combined_entry)\n",
    "        else:\n",
    "            # If any of the dictionaries doesn't have a corresponding entry, add only the entry from attended_data_dic\n",
    "            combined_dict[location_id].append(entry1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.5  Covert the output into DFs and store in spearate csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the keys (location_ids) in combined_dict\n",
    "for location_id, combined_data in combined_dict.items():\n",
    "    # Create a dataframe for each store\n",
    "    df = pd.DataFrame(combined_data)\n",
    "    # Set the 'date' column as the index \n",
    "    df.set_index('date', inplace=True)\n",
    "    # Store the dataframe in a csv file with the location_id specified in the file name\n",
    "    df.to_csv(f'{demand_data_wd}/{location_id}_beam_analysis_with_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4. Plotting and interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take location_id == store_0 as an example and convert it into a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_analysis = pd.DataFrame(analyses_dic['store_0']['dates'])\n",
    "# Extract required columns\n",
    "beam_analysis = beam_analysis[['date', 'actual_demand', 'baseline_demand', 'remainder', 'impact']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please note the demand time series is decomposed into baseline demand time series and remainder time series. \n",
    "#### Baseline demand:  The baseline demand time series represents the estimated demand and contains information about trends and seasonality within the demand time series.\n",
    "#### Event imapct: For events belonging to attended categories, the corresponding daily total attendance represents the event impact.\n",
    "#### Reminder: The remainder is the difference between the demand time series and the baseline demand time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "name": "demand",
         "type": "scatter",
         "x": [
          "2017-10-02",
          "2017-10-03",
          "2017-10-04",
          "2017-10-05",
          "2017-10-06",
          "2017-10-07",
          "2017-10-08",
          "2017-10-09",
          "2017-10-10",
          "2017-10-11",
          "2017-10-12",
          "2017-10-13",
          "2017-10-14",
          "2017-10-15",
          "2017-10-16",
          "2017-10-17",
          "2017-10-18",
          "2017-10-19",
          "2017-10-20",
          "2017-10-21",
          "2017-10-22",
          "2017-10-23",
          "2017-10-24",
          "2017-10-25",
          "2017-10-26",
          "2017-10-27",
          "2017-10-28",
          "2017-10-29",
          "2017-10-30",
          "2017-10-31"
         ],
         "y": [
          3950,
          3679,
          3517,
          1787,
          1359,
          1430,
          1319,
          1419,
          1647,
          2038,
          2288,
          1613,
          1811,
          1414,
          1451,
          1727,
          1915,
          1750,
          1516,
          1703,
          1461,
          1511,
          1830,
          2104,
          2372,
          1597,
          1400,
          1481,
          1622,
          1552
         ]
        },
        {
         "mode": "lines+markers",
         "name": "estimated_demand",
         "type": "scatter",
         "x": [
          "2017-10-02",
          "2017-10-03",
          "2017-10-04",
          "2017-10-05",
          "2017-10-06",
          "2017-10-07",
          "2017-10-08",
          "2017-10-09",
          "2017-10-10",
          "2017-10-11",
          "2017-10-12",
          "2017-10-13",
          "2017-10-14",
          "2017-10-15",
          "2017-10-16",
          "2017-10-17",
          "2017-10-18",
          "2017-10-19",
          "2017-10-20",
          "2017-10-21",
          "2017-10-22",
          "2017-10-23",
          "2017-10-24",
          "2017-10-25",
          "2017-10-26",
          "2017-10-27",
          "2017-10-28",
          "2017-10-29",
          "2017-10-30",
          "2017-10-31"
         ],
         "y": [
          3306.0579876097836,
          3400.855159763927,
          3039.7336459192616,
          2417.9628216785222,
          1798.312046139129,
          1404.884574642797,
          1374.9008986338963,
          1639.3710277838368,
          2005.7651274024454,
          2241.9398716218097,
          2208.3698096689204,
          1954.1786090401856,
          1639.7053469557698,
          1467.3886198327823,
          1523.1803702836992,
          1667.2827606432043,
          1831.6998865604687,
          1916.0547216319837,
          1967.2508607128866,
          1983.1801419117119,
          1994.8418705200368,
          2018.2348211045007,
          2071.3800093321042,
          2013.7833552452648,
          1884.8154965772178,
          1720.56868201726,
          1644.0937994976832,
          1668.745843545834,
          1748.0203572268033,
          1786.9133915326993
         ]
        },
        {
         "mode": "lines+markers",
         "name": "impact",
         "type": "scatter",
         "x": [
          "2017-10-02",
          "2017-10-03",
          "2017-10-04",
          "2017-10-05",
          "2017-10-06",
          "2017-10-07",
          "2017-10-08",
          "2017-10-09",
          "2017-10-10",
          "2017-10-11",
          "2017-10-12",
          "2017-10-13",
          "2017-10-14",
          "2017-10-15",
          "2017-10-16",
          "2017-10-17",
          "2017-10-18",
          "2017-10-19",
          "2017-10-20",
          "2017-10-21",
          "2017-10-22",
          "2017-10-23",
          "2017-10-24",
          "2017-10-25",
          "2017-10-26",
          "2017-10-27",
          "2017-10-28",
          "2017-10-29",
          "2017-10-30",
          "2017-10-31"
         ],
         "y": [
          75818,
          65100,
          72005,
          81428,
          84394,
          24916,
          25260,
          21236,
          12777,
          12969,
          18161,
          15535,
          39124,
          38916,
          19626,
          8421,
          8196,
          20627,
          43901,
          13966,
          24559,
          11818,
          11329,
          8202,
          21867,
          23867,
          38100,
          30961,
          5329,
          1894
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 1000,
        "xaxis": {
         "domain": [
          0,
          0.7
         ]
        },
        "yaxis": {
         "title": {
          "text": "demand"
         }
        },
        "yaxis2": {
         "anchor": "x",
         "overlaying": "y",
         "side": "right",
         "title": {
          "text": "impact"
         }
        },
        "yaxis3": {
         "anchor": "free",
         "overlaying": "y",
         "position": 0.85,
         "side": "right",
         "title": {
          "text": "public_holidays"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=beam_analysis.date, y=beam_analysis.actual_demand, name='demand',mode='lines+markers')\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=beam_analysis.date, y=beam_analysis.baseline_demand, name=\"estimated_demand\",mode='lines+markers')\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=beam_analysis.date, y=beam_analysis.impact, name=\"impact\",\n",
    "    yaxis=\"y2\",mode='lines+markers'\n",
    "    # ,fill='tozeroy'\n",
    "))\n",
    "\n",
    "# Create axis objects\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        domain=[0.0, 0.7]\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"demand\"\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        title=\"impact\",\n",
    "        anchor=\"x\",\n",
    "        overlaying=\"y\",\n",
    "        side=\"right\",\n",
    "    ),\n",
    "    yaxis3=dict(\n",
    "        title=\"public_holidays\",\n",
    "        anchor=\"free\",\n",
    "        overlaying=\"y\",\n",
    "        side=\"right\",\n",
    "        position=0.85\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update layout properties\n",
    "fig.update_layout(\n",
    "    width=1000,\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "# HTML(fig.to_html())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
